{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5ae8916",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'in' is not a valid parameter name",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#!pip install spacy\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#!pip install es_core_news_sm\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mes_core_news_sm\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/__init__.py:14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m prefer_gpu, require_gpu, require_cpu  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcli\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m info  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mglossary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m explain  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/pipeline/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattributeruler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AttributeRuler\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdep_parser\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DependencyParser\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mentity_linker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EntityLinker\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/pipeline/attributeruler.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msrsly\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipe\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Errors\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_examples, Example\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/pipeline/pipe.pyx:8\u001b[0m, in \u001b[0;36minit spacy.pipeline.pipe\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/training/__init__.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatchers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m minibatch_by_padded_size, minibatch_by_words  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloggers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m console_logger, wandb_logger_v3 \u001b[38;5;28;01mas\u001b[39;00m wandb_logger  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_copy_from_base_model\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/training/callbacks.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callable, Optional\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Errors\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlanguage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Language\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model, registry, logger\n\u001b[1;32m      7\u001b[0m \u001b[38;5;129m@registry\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspacy.copy_from_base_model.v1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_copy_from_base_model\u001b[39m(\n\u001b[1;32m      9\u001b[0m     tokenizer: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m     vocab: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     11\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Callable[[Language], Language]:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/language.py:25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipe_analysis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_attrs, analyze_pipes, print_pipe_analysis\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Example, validate_examples\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minitialize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m init_vocab, init_tok2vec\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscorer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Scorer\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m registry, SimpleFrozenList, _pipe, raise_error\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/training/initialize.py:14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m islice\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpretrain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_tok2vec_ref\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlookups\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Lookups\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Vectors\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/training/pretrain.py:16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Errors\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokens\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Doc\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschemas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConfigSchemaPretrain\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m registry, load_model_from_config, dot_to_object\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpretrain\u001b[39m(\n\u001b[1;32m     21\u001b[0m     config: Config,\n\u001b[1;32m     22\u001b[0m     output_dir: Path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     silent: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     27\u001b[0m ):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spacy/schemas.py:156\u001b[0m\n\u001b[1;32m    152\u001b[0m         obj \u001b[38;5;241m=\u001b[39m converted\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m validate(TokenPatternSchema, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpattern\u001b[39m\u001b[38;5;124m\"\u001b[39m: obj})\n\u001b[0;32m--> 156\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTokenPatternString\u001b[39;00m(BaseModel):\n\u001b[1;32m    157\u001b[0m     REGEX: Optional[StrictStr] \u001b[38;5;241m=\u001b[39m Field(\u001b[38;5;28;01mNone\u001b[39;00m, alias\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    158\u001b[0m     IN: Optional[List[StrictStr]] \u001b[38;5;241m=\u001b[39m Field(\u001b[38;5;28;01mNone\u001b[39;00m, alias\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pydantic/main.py:369\u001b[0m, in \u001b[0;36mModelMetaclass.__new__\u001b[0;34m(mcs, name, bases, namespace, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(mcs, name, bases, new_namespace, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    368\u001b[0m \u001b[38;5;66;03m# set __signature__ attr only for model class, but not for its instances\u001b[39;00m\n\u001b[0;32m--> 369\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__signature__ \u001b[38;5;241m=\u001b[39m ClassAttribute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__signature__\u001b[39m\u001b[38;5;124m'\u001b[39m, generate_model_signature(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m, fields, config))\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pydantic/utils.py:231\u001b[0m, in \u001b[0;36mgenerate_model_signature\u001b[0;34m(init, fields, config)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[38;5;66;03m# TODO: replace annotation with actual expected types once #1055 solved\u001b[39;00m\n\u001b[1;32m    230\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m: field\u001b[38;5;241m.\u001b[39mdefault} \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m field\u001b[38;5;241m.\u001b[39mrequired \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m--> 231\u001b[0m         merged_params[param_name] \u001b[38;5;241m=\u001b[39m Parameter(\n\u001b[1;32m    232\u001b[0m             param_name, Parameter\u001b[38;5;241m.\u001b[39mKEYWORD_ONLY, annotation\u001b[38;5;241m=\u001b[39mfield\u001b[38;5;241m.\u001b[39mouter_type_, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    233\u001b[0m         )\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mextra \u001b[38;5;129;01mis\u001b[39;00m config\u001b[38;5;241m.\u001b[39mextra\u001b[38;5;241m.\u001b[39mallow:\n\u001b[1;32m    236\u001b[0m     use_var_kw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/inspect.py:2725\u001b[0m, in \u001b[0;36mParameter.__init__\u001b[0;34m(self, name, kind, default, annotation)\u001b[0m\n\u001b[1;32m   2723\u001b[0m is_keyword \u001b[38;5;241m=\u001b[39m iskeyword(name) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kind \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _POSITIONAL_ONLY\n\u001b[1;32m   2724\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_keyword \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m name\u001b[38;5;241m.\u001b[39misidentifier():\n\u001b[0;32m-> 2725\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m is not a valid parameter name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name))\n\u001b[1;32m   2727\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n",
      "\u001b[0;31mValueError\u001b[0m: 'in' is not a valid parameter name"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "#!pip install spacy\n",
    "import spacy\n",
    "#!pip install es_core_news_sm\n",
    "import es_core_news_sm\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nlp = es_core_news_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decd4f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos\n",
    "train_df = pd.read_csv('training.txt', sep='\\t', header=None, names=['id', 'label', 'tweet'])\n",
    "dev_df = pd.read_csv('development.txt', sep='\\t', header=None, names=['id', 'label', 'tweet'])\n",
    "test_df = pd.read_csv('test.txt', sep='\\t', header=None, names=['id', 'label', 'tweet'])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106d8c38",
   "metadata": {},
   "source": [
    "Diccionario de polaridad, lo introduciremos al pipeline como otra feature incluida en nuestro clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def090e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_polarity_dict(file_path):\n",
    "    polarity_dict = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) == 2:\n",
    "                word, polarity = parts\n",
    "                try:\n",
    "                    polarity_dict[word] = float(polarity)\n",
    "                except ValueError:\n",
    "                    continue  \n",
    "    return polarity_dict\n",
    "\n",
    "polarity_dict = load_polarity_dict(\"../corpus/ElhPolar_esV1.lex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641260bc",
   "metadata": {},
   "source": [
    "Preproceso de los texto en los que realizaremos las siguientes labores:\n",
    "1. eliminamos las menciones\n",
    "2. eliminamos caracteres especiales que no nos sirven\n",
    "3. convertimos a minusculas, para mayor facilidad de encontrar la misma palabra ej: CASA Casa casa\n",
    "4. Tokenizar los textos en palabras\n",
    "5. Lemmatizar los textos con spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4a7de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, stopwords, nlp):\n",
    "        self.stopwords = stopwords\n",
    "        self.nlp = nlp\n",
    "\n",
    "    def preprocess(self, text):\n",
    "        text = re.sub(r'@\\w+', '', text)  # Eliminar menciones\n",
    "        text = re.sub(r'[^a-zA-ZáéíóúÁÉÍÓÚñÑ\\s]', '', text)  # Eliminar caracteres especiales\n",
    "        text = text.lower()  # Convertir a minúsculas\n",
    "        doc = self.nlp(text)  # Procesar el texto con spaCy\n",
    "        tokens = [token.lemma_ for token in doc if token.text not in self.stopwords and not token.is_punct and not token.is_stop]  # Lematización y eliminación de stopwords y signos de puntuación\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.apply(self.preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74d00f6",
   "metadata": {},
   "source": [
    "Clase para extraer el score total de los textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f788aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolarityScoreExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, polarity_dict):\n",
    "        self.polarity_dict = polarity_dict\n",
    "\n",
    "    def polarity_score(self, text):\n",
    "        words = text.split()\n",
    "        score = sum(self.polarity_dict.get(word, 0) for word in words)\n",
    "        return score\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return pd.DataFrame(X.apply(self.polarity_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96705920",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8925c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de stopwords en español\n",
    "spanish_stopwords = set(stopwords.words('spanish'))\n",
    "preprocessor = TextPreprocessor(spanish_stopwords, nlp)\n",
    "train_df['tweet'] = preprocessor.transform(train_df['tweet'])\n",
    "dev_df['tweet'] = preprocessor.transform(dev_df['tweet'])\n",
    "test_df['tweet'] = preprocessor.transform(test_df['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd7878c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat dev and train\n",
    "combined_df = pd.concat([train_df, dev_df])\n",
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3424ee9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ade2e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = combined_df['tweet']\n",
    "y_train = combined_df['label']\n",
    "X_test = test_df['tweet']\n",
    "X_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0b6f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='f1_weighted')\n",
    "print(f'Cross-validation F1 scores: {cv_scores}')\n",
    "print(f'Mean cross-validation F1 score: {cv_scores.mean()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115c2e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict test\n",
    "y_pred_test = pipeline.predict(X_test)\n",
    "\n",
    "# Results in df\n",
    "results = pd.DataFrame({'id': test_df['id'], 'label': y_pred_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d344dbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame en un archivo de texto con el formato requerido\n",
    "results.to_csv('resultado2.txt', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086d7877",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
